{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch for Beginners\n",
    "\n",
    "lets explore what pytorch offers\n",
    "\n",
    "lots of this notebook is borrowed from jeremy howards great tutorial! https://pytorch.org/tutorials/beginner/nn_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]), array([[2.71828183],\n",
       "        [2.71828183],\n",
       "        [2.71828183],\n",
       "        [2.71828183]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1.0,1.0,1.0,1.0])\n",
    "a, np.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor([2.7183, 2.7183, 2.7183, 2.7183]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.0,1.0,1.0,1.0])\n",
    "a, a.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "FILENAME = \"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### unzip data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "we have downloaded the gzipped pickle now we need to unzip it and load it into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9f3ea48da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f52bc8940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0].reshape(28, 28)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### convert our numpy arrays into torch tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset X shape:  torch.Size([50000, 784])\n",
      "The classes of number:  tensor(0) tensor(9)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# get our sample size m and input size n\n",
    "m, n = x_train.shape\n",
    "\n",
    "print('Full dataset X shape: ',x_train.shape)\n",
    "print('The classes of number: ',y_train.min(), y_train.max())\n",
    "\n",
    "print(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression from scratch \n",
    "\n",
    "basically a neural net with no hidden layers. A linear transformation and a activation function\n",
    "\n",
    "like the equation for a line:\n",
    "\n",
    "$ y = ax + b $\n",
    "\n",
    "expect our input is not just 1 number, its a vector x\n",
    "in our case its a vector of length 784\n",
    "\n",
    "$ x = \\begin{bmatrix} 1 \\\\ 2 \\\\ \\vdots \\\\ 784 \\end{bmatrix} $\n",
    "\n",
    "so now we have\n",
    "\n",
    "$ \\hat{y} = wx + b   $\n",
    "\n",
    "where w and x are vectors of length 784 and b is scalar ( just a number )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_d, output_d = 784, 10\n",
    "\n",
    "weights = torch.randn(input_d, output_d)\n",
    "weights.requires_grad_() # mutates weights tensor to use grads\n",
    "\n",
    "bias = torch.zeros(output_d, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check out tensors for grad\n",
    "weights.requires_grad, bias.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define function vectorized or GPU calculation like you can in numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## our model can be written simply as the basic calculations of\n",
    "# \n",
    "\n",
    "def model(x_batch):\n",
    "    a = x_batch @ weights + bias\n",
    "    return log_softmax(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward pass\n",
    "\n",
    "predict for a minibatch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.1668e+01, -2.4357e+01, -3.6294e+01, -8.2376e+00, -2.0591e+01,\n",
       "         -9.2697e-04, -7.3537e+00, -1.1239e+01, -2.6452e+01, -2.1156e+01],\n",
       "        grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "\n",
    "# grab a minibatch and perform a forward pass \n",
    "# xb = batch of x\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function\n",
    "\n",
    "we need loss function before we can calculate our gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.6650, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy metric\n",
    "\n",
    "we should also use accurarcy metric to tell us how often our model is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "now we can get to gradient descent\n",
    "\n",
    "What we need to descent the gradient\n",
    "- model\n",
    "- loss\n",
    "- backward propagation \n",
    "- update our models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "our loss:,  tensor(0.3419, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.3509, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.2819, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.4068, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.3016, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.6158, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.2643, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.6440, grad_fn=<NegBackward>)\n",
      "epoch:  1\n",
      "our loss:,  tensor(0.2650, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.3182, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.2335, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.3850, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.2683, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.5611, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.2433, grad_fn=<NegBackward>)\n",
      "our loss:,  tensor(0.5902, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "# from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('epoch: ',epoch)\n",
    "    for i in range((m - 1) // bs + 1):\n",
    "        #         set_trace()\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('our loss:, ', loss)\n",
    "            \n",
    "        # Pytorch protect updates to weights because otherwise these calculations should be part of the computation graph!\n",
    "        # so we need to tell pytorch that we dont care about the following changes being tracked in .grad\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5727, grad_fn=<NegBackward>) tensor(0.8281)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor with \n",
    "# nn.Module, nn.Linear, nn.Functional \n",
    "\n",
    "Heaps of commonly used loss functions and NN layer patterns are already implemented in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3288, grad_fn=<NllLossBackward>) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with model.parameters() \n",
    "Before we had to update every weight by name, now we can retreive them all with the model.parameters() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        for i in range((m - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print('our loss:, ', loss)\n",
    "                \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                #re write to use model.parameters()\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "our loss:,  tensor(2.3400, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3126, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3004, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3911, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.2335, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3862, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.2601, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3791, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1110, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3455, grad_fn=<NllLossBackward>) tensor(0.1250)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, opt, loss_func):\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        for i in range((m - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('our loss:, ', loss)\n",
    "            \n",
    "            # our optimizer \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "our loss:,  tensor(0.2758, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.2622, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.1931, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3439, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.2108, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3546, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.2273, grad_fn=<NllLossBackward>)\n",
      "our loss:,  tensor(0.3586, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(1, model, opt, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Datasets\n",
    "\n",
    "abstract class where you need to implement\n",
    "\n",
    "__len__ & __getitem__ methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataloader\n",
    "\n",
    "manages getting batches for our training loop from our dataloader\n",
    "\n",
    "returns a python interator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorDataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor(5))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_ds[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([16, 784])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and validation Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x_train, y_train, bs):\n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "    valid_ds = TensorDataset(x_valid, y_valid)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
    "    return train_dl, valid_dl\n",
    "\n",
    "train_dl, valid_dl = get_data(x_train, y_train, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    y_pred = model(xb)\n",
    "    loss = loss_func(y_pred, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb), y_pred, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums, preds, ys = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        validation_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        \n",
    "        \n",
    "        accs = [ accuracy(yhat, y).item() for yhat, y in zip(preds, ys)]\n",
    "        \n",
    "        print(epoch, validation_loss, np.sum(accs)/ len(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.30248018956184386 0.9149525316455697\n",
      "1 0.3148197050571442 0.9100079113924051\n",
      "2 0.3267840696334839 0.9056566455696202\n",
      "3 0.27755440430641176 0.9240506329113924\n",
      "4 0.29774869232177736 0.9154469936708861\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "#         print(self.training)\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.adaptive_avg_pool2d(xb, 1)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnist_CNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mnist_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2702548347473144 0.5892998417721519\n",
      "1 0.6664396021842957 0.7948971518987342\n",
      "2 0.43367488927841186 0.8750988924050633\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "fit(3, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22429709463119507 0.9354232594936709\n",
      "1 0.2050009204864502 0.9424446202531646\n",
      "2 0.2072999261856079 0.9428401898734177\n"
     ]
    }
   ],
   "source": [
    "fit(3, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.adaptive_avg_pool2d??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 2-dimensional input of size [64, 784] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-ad19b11fd90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 2-dimensional input of size [64, 784] instead"
     ]
    }
   ],
   "source": [
    "model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(lambda xb: xb.view(-1, 1, 28, 28)),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda xb: xb.view(-1, xb.size(1)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3496015674591064 0.5609177215189873\n",
      "1 0.6757259038925171 0.7830300632911392\n",
      "2 0.44800182189941407 0.8636273734177216\n"
     ]
    }
   ],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "fit(3, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need all our tensor ops to be on the GPU \n",
    "\n",
    "Otherwise we will get an error \n",
    "\n",
    "This means we have to put our dataset onto the gpu as well as our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(x, y):\n",
    "    return x.to(dev), y.to(dev)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_data(x_train, y_train, 64)\n",
    "train_dl = WrappedDataLoader(train_dl, to_device)\n",
    "valid_dl = WrappedDataLoader(valid_dl, to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.20664597454071046 0.9376977848101266\n",
      "1 0.2013221917152405 0.9416534810126582\n",
      "2 0.199952001953125 0.9433346518987342\n",
      "3 0.18992808513641357 0.9444224683544303\n",
      "4 0.18371812086105346 0.9486748417721519\n",
      "5 0.1758351182937622 0.9511471518987342\n",
      "6 0.16914637775421143 0.9523338607594937\n",
      "7 0.1881415760040283 0.9475870253164557\n",
      "8 0.18738684339523315 0.9472903481012658\n",
      "9 0.17089933853149414 0.9521360759493671\n",
      "CPU times: user 55.7 s, sys: 1min 52s, total: 2min 47s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
