{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "for beginners.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N77opbPvaDzd",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch for Beginners\n",
        "\n",
        "lets explore what pytorch offers\n",
        "\n",
        "lots of this notebook is borrowed from jeremy howards great tutorial! https://pytorch.org/tutorials/beginner/nn_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u27c1DSGaDzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgwQH3rbaDzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import pickle\n",
        "import gzip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Cw3dFnaDzl",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc37466e-53a7-4b2a-b2bd-cca85e89c3dc"
      },
      "source": [
        "a = np.array([1.0,1.0,1.0,1.0])\n",
        "a, np.exp(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 1., 1.]),\n",
              " array([2.71828183, 2.71828183, 2.71828183, 2.71828183]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTWBEmNkaDzq",
        "colab_type": "code",
        "colab": {},
        "outputId": "6cb3c747-cea2-4cef-846a-8514e684e319"
      },
      "source": [
        "a = torch.tensor([1.0,1.0,1.0,1.0])\n",
        "a, a.exp()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor([2.7183, 2.7183, 2.7183, 2.7183]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPuU2zECaDzt",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9663ba5-ace1-4b84-efc7-2efc27bf3ef9"
      },
      "source": [
        "a = torch.randn(2,2)\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrpIxq4aaDzw",
        "colab_type": "code",
        "colab": {},
        "outputId": "91dbb284-5222-4650-84ca-8c4d91afbc78"
      },
      "source": [
        "b = torch.full([2,1], 99)\n",
        "b.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32l4Jw5vaDz0",
        "colab_type": "code",
        "colab": {},
        "outputId": "4c1bbc85-3093-4b8a-8b12-27f70c87459c"
      },
      "source": [
        "torch.add(b,a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[99.4201, 99.1165],\n",
              "        [98.8650, 98.2838]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEYW8azcaDz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "FILENAME = \"mnist.pkl.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPe-u1YZaDz6",
        "colab_type": "text"
      },
      "source": [
        "## MNIST data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "RtNZ0KfZaDz6",
        "colab_type": "text"
      },
      "source": [
        "### download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "mGr48NQtaDz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0dxdq3OaDz9",
        "colab_type": "text"
      },
      "source": [
        "### unzip data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUwD_er1aDz-",
        "colab_type": "text"
      },
      "source": [
        "we have downloaded the gzipped pickle now we need to unzip it and load it into python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqH96wbvaDz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Zfs4pMaD0B",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7900988-8f42-4baf-8757-60b1e55060b1"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 784), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrkMGAfQaD0E",
        "colab_type": "text"
      },
      "source": [
        "### look at data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAtnAy-QaD0E",
        "colab_type": "code",
        "colab": {},
        "outputId": "26278df6-1489-48ff-a76a-fd9360a3be85"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gob9Ho-oaD0H",
        "colab_type": "code",
        "colab": {},
        "outputId": "70f14ad5-e139-4b89-cfe4-d3c69122f8a3"
      },
      "source": [
        "img = x_train[0].reshape(28, 28)\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9ee6d881d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9ee6f4dac8>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9muvuZEcaD0K",
        "colab_type": "text"
      },
      "source": [
        "### convert our numpy arrays into torch tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huZff9qFaD0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJu4GDuGaD0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYUQw3waD0T",
        "colab_type": "code",
        "colab": {},
        "outputId": "a97e09f6-163a-45e9-db5d-49346e3fb34e"
      },
      "source": [
        "# get our sample size m and input size n\n",
        "m, n = x_train.shape\n",
        "\n",
        "print('Full dataset X shape: ',x_train.shape)\n",
        "print('The classes of number: ',y_train.min(), y_train.max())\n",
        "\n",
        "print(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Full dataset X shape:  torch.Size([50000, 784])\n",
            "The classes of number:  tensor(0) tensor(9)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMPMpu_YaD0X",
        "colab_type": "text"
      },
      "source": [
        "## Logistic regression from scratch \n",
        "\n",
        "basically a neural net with no hidden layers. A linear transformation and a activation function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh3IBXABaD0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = wx + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSyKCzE9aD0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_d, output_d = 784, 10\n",
        "\n",
        "weights = torch.randn(input_d, output_d)\n",
        "weights.requires_grad_() # mutates weights tensor to use grads\n",
        "\n",
        "bias = torch.zeros(output_d, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOsTdPFRaD0g",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b4703d6-ca7f-4b55-938c-67b0c5658a86"
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnni3X8iaD0j",
        "colab_type": "code",
        "colab": {},
        "outputId": "923b4618-0e3d-40ca-a83d-1cf5bc722523"
      },
      "source": [
        "# we can check out tensors for grad\n",
        "weights.requires_grad, bias.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtl-EpFyaD0n",
        "colab_type": "text"
      },
      "source": [
        "You can define function vectorized or GPU calculation like you can in numpy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0-WzjugaD0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdukH1DpaD0q",
        "colab_type": "code",
        "colab": {},
        "outputId": "22fefad6-7d78-47f3-f073-fe141901ab6a"
      },
      "source": [
        "torch.randn(40).unsqueeze(-1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mppCL3faD0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33TJkDYRaD0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## our model can be written simply as the basic calculations of\n",
        "# \n",
        "\n",
        "def model(x_batch):\n",
        "    a = x_batch @ weights + bias\n",
        "    return log_softmax(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KovBear5aD0x",
        "colab_type": "text"
      },
      "source": [
        "### forward pass\n",
        "\n",
        "predict for a minibatch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySHKYgDQaD0y",
        "colab_type": "code",
        "colab": {},
        "outputId": "56eaf0d8-da0c-4a6a-a0a2-22f22d7cbf16"
      },
      "source": [
        "bs = 64\n",
        "\n",
        "# grab a minibatch and perform a forward pass \n",
        "# xb = batch of x\n",
        "xb = x_train[0:bs]\n",
        "preds = model(xb)\n",
        "\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ -8.8191, -19.9569,  -5.2772,  -4.6389,  -3.3530, -19.1895, -10.8294,\n",
              "          -0.9634,  -0.5648, -19.5093], grad_fn=<SelectBackward>),\n",
              " torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBPU5RmdaD00",
        "colab_type": "text"
      },
      "source": [
        "### loss function\n",
        "\n",
        "we need loss function before we can calculate our gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SquRVX8uaD01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target):\n",
        "    return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uswoHbIwaD05",
        "colab_type": "code",
        "colab": {},
        "outputId": "a16e7b3c-93bb-4eeb-ba48-d3de56ac6d7b"
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "print(loss_func(preds, yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(15.3109, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJOSUliQaD08",
        "colab_type": "text"
      },
      "source": [
        "### accuracy metric\n",
        "\n",
        "we should also use accurarcy metric to tell us how often our model is correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKOJa8FpaD09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qu7UFD9aD1A",
        "colab_type": "code",
        "colab": {},
        "outputId": "f4f9cf69-98e7-4f66-f4da-8c418098fec2"
      },
      "source": [
        "print(accuracy(preds, yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWanLobsaD1C",
        "colab_type": "text"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "now we can get to gradient descent\n",
        "\n",
        "What we need to descent the gradient\n",
        "- model\n",
        "- loss\n",
        "- backward propagation \n",
        "- update our models weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEfaAaWbaD1D",
        "colab_type": "code",
        "colab": {},
        "outputId": "e88b8649-d45d-4776-bb17-3afd9a3b3546"
      },
      "source": [
        "# from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 2  # how many epochs to train for\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('epoch: ',epoch)\n",
        "    for i in range((m - 1) // bs + 1):\n",
        "        #         set_trace()\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('our loss:, ', loss)\n",
        "            \n",
        "        # Pytorch protect updates to weights because otherwise these calculations should be part of the computation graph!\n",
        "        # so we need to tell pytorch that we dont care about the following changes being tracked in .grad\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "our loss:,  tensor(15.3109, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(1.5262, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(1.0232, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(1.1546, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.6248, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.6692, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.5976, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.8353, grad_fn=<NegBackward>)\n",
            "epoch:  1\n",
            "our loss:,  tensor(0.8311, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.5651, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.4147, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.7224, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.3328, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.5458, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.3493, grad_fn=<NegBackward>)\n",
            "our loss:,  tensor(0.6153, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqpWskcaaD1F",
        "colab_type": "code",
        "colab": {},
        "outputId": "83a7bf47-a85c-4574-bbc0-9fd16fb1b462"
      },
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3408, grad_fn=<NegBackward>) tensor(0.9375)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_nWwYB4aD1H",
        "colab_type": "text"
      },
      "source": [
        "# Refactor with \n",
        "# nn.Module, nn.Linear, nn.Functional \n",
        "\n",
        "Heaps of commonly used loss functions and NN layer patterns are already implemented in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3uDQWGaD1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMmdoVJWaD1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq2XpFzEaD1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Mnist_Logistic()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tqMSdt_aD1Q",
        "colab_type": "code",
        "colab": {},
        "outputId": "bad35dbb-8b13-4e44-c3eb-f4bda5749cf1"
      },
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2551, grad_fn=<NllLossBackward>) tensor(0.1250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldXv2U6uaD1S",
        "colab_type": "text"
      },
      "source": [
        "### with model.parameters() \n",
        "Before we had to update every weight by name, now we can retreive them all with the model.parameters() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKuVYef4aD1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fit(epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        for i in range((m - 1) // bs + 1):\n",
        "            start_i = i * bs\n",
        "            end_i = start_i + bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                print('our loss:, ', loss)\n",
        "                \n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                #re write to use model.parameters()\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0199x7vbaD1W",
        "colab_type": "code",
        "colab": {},
        "outputId": "c53d32e4-b896-4baa-f98c-78a4cd710c62"
      },
      "source": [
        "fit(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "our loss:,  tensor(2.3067, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3177, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.2934, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3927, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.2343, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3843, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.2637, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3785, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d7ePCPbaD1b",
        "colab_type": "code",
        "colab": {},
        "outputId": "c120c200-ddd1-45fc-f550-e28cc9535580"
      },
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1129, grad_fn=<NllLossBackward>) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vaotgBxaD1d",
        "colab_type": "text"
      },
      "source": [
        "### Now use Optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODLCXEaHaD1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HodkKlVOaD1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = Mnist_Logistic()\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edOpHQURaD1j",
        "colab_type": "code",
        "colab": {},
        "outputId": "0eb1a4cb-3cce-4572-8ff7-aea3cf54cfcb"
      },
      "source": [
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.4087, grad_fn=<NllLossBackward>) tensor(0.1250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSktYTOzaD1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, opt, loss_func):\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        for i in range((m - 1) // bs + 1):\n",
        "            start_i = i * bs\n",
        "            end_i = start_i + bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print('our loss:, ', loss)\n",
        "            \n",
        "            # our optimizer \n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsDlzzNvaD1n",
        "colab_type": "code",
        "colab": {},
        "outputId": "2ddba5b1-b79d-4601-da2b-01f69dfe4bc0"
      },
      "source": [
        "fit(1, model, opt, loss_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "our loss:,  tensor(2.3653, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3166, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3007, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3913, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.2403, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3814, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.2598, grad_fn=<NllLossBackward>)\n",
            "our loss:,  tensor(0.3803, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxTO8wPIaD1q",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch Datasets\n",
        "\n",
        "abstract class where you need to implement\n",
        "\n",
        "__len__ & __getitem__ methods "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QTNWc7jaD1r",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch Dataloader\n",
        "\n",
        "manages getting batches for our training loop from our dataloader\n",
        "\n",
        "returns a python interator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN4OxB4BaD1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHPXEz4QaD1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TensorDataset??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz8hN0S0aD1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = TensorDataset(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOmxkhqFaD12",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5f23c23-b1cd-4766-f099-0d21961c9727"
      },
      "source": [
        "x, y = train_ds[0]\n",
        "x.shape, y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), tensor(5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwYadRhOaD16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pMHX9gzfaD17",
        "colab_type": "code",
        "colab": {},
        "outputId": "48ce84e0-4540-41f4-f2d2-5ad5b1fc8684"
      },
      "source": [
        "for xb, yb in train_dl:\n",
        "    print(xb.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([256, 784])\n",
            "torch.Size([80, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFsx0oaAaD1-",
        "colab_type": "text"
      },
      "source": [
        "### train and validation Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka_6wTx6aD1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(x_train, y_train, bs):\n",
        "    train_ds = TensorDataset(x_train, y_train)\n",
        "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "\n",
        "    valid_ds = TensorDataset(x_valid, y_valid)\n",
        "    valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
        "    return train_dl, valid_dl\n",
        "\n",
        "train_dl, valid_dl = get_data(x_train, y_train, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSREE13waD2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    y_pred = model(xb)\n",
        "    loss = loss_func(y_pred, yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb), y_pred, yb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0BbNT_saD2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums, preds, ys = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        validation_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "        \n",
        "        \n",
        "        accs = [ accuracy(yhat, y).item() for yhat, y in zip(preds, ys)]\n",
        "        \n",
        "        print(epoch, validation_loss, np.sum(accs)/ len(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VxyTPQ5aD2F",
        "colab_type": "text"
      },
      "source": [
        "combine it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLfC_vKFaD2G",
        "colab_type": "code",
        "colab": {},
        "outputId": "2a6f5fa7-8973-4470-e01e-a41bf28ee171"
      },
      "source": [
        "model, opt = get_model()\n",
        "fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.2902140532016754 0.9165348101265823\n",
            "1 0.3350223633289337 0.9058544303797469\n",
            "2 0.2991545620441437 0.9172270569620253\n",
            "3 0.32811769943237307 0.9049643987341772\n",
            "4 0.28793505349159243 0.9198971518987342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pvn0EdMaD2J",
        "colab_type": "text"
      },
      "source": [
        "###  CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etpoUJNDaD2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        xb = xb.view(-1, 1, 28, 28)\n",
        "        xb = F.relu(self.conv1(xb))\n",
        "        xb = F.relu(self.conv2(xb))\n",
        "        xb = F.relu(self.conv3(xb))\n",
        "        xb = F.adaptive_avg_pool2d(xb, 1)\n",
        "        return xb.view(-1, xb.size(1))\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-pVoDwBaD2L",
        "colab_type": "code",
        "colab": {},
        "outputId": "9b140369-85a4-41d7-fc42-3b2baffd70f5"
      },
      "source": [
        "Mnist_CNN()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mnist_CNN(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (conv3): Conv2d(16, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGLvxgt0aD2M",
        "colab_type": "code",
        "colab": {},
        "outputId": "aa7ca6cb-1481-4bd2-9d08-b05b4eff991c"
      },
      "source": [
        "model = Mnist_CNN()\n",
        "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "fit(3, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.4628131328582763 0.5412381329113924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-377-98fe5fab9821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-373-6e867c7b3339>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-372-8158abc2265a>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-375-1d84d1b0d22d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVP4eCtMaD2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit(3, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GMS4NOAaD2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F.adaptive_avg_pool2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpEaet7IaD2U",
        "colab_type": "text"
      },
      "source": [
        "### nn.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHef9gfIaD2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NWzmc1CaD2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = next(iter(train_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMi8S3owaD2X",
        "colab_type": "code",
        "colab": {},
        "outputId": "18401068-fcf2-435e-b7ba-7ec71ec81359"
      },
      "source": [
        "model(xb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 2-dimensional input of size [64, 784] instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-380-ad19b11fd90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 2-dimensional input of size [64, 784] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7XyPGlMaD2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDt38OgvaD2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    Lambda(lambda xb: xb.view(-1, 1, 28, 28)),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(lambda xb: xb.view(-1, xb.size(1)))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ot-NoFaD2b",
        "colab_type": "code",
        "colab": {},
        "outputId": "251df7a3-33c0-436a-ac4e-d8dd394be47b"
      },
      "source": [
        "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "train_dl, valid_dl = get_data(x_train, y_train, 1024)\n",
        "\n",
        "fit(3, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2.3019332149505614 0.10640815198421479\n",
            "1 2.3015339069366454 0.10640815198421479\n",
            "2 2.3010899620056153 0.10640815198421479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjYO6wnWaD2d",
        "colab_type": "text"
      },
      "source": [
        "# GPU!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdXPzAFsaD2e",
        "colab_type": "code",
        "colab": {},
        "outputId": "bf95898a-c7d1-4d83-d8df-83440d3535ff"
      },
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3930"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FN8O26aD2f",
        "colab_type": "code",
        "colab": {},
        "outputId": "7cdbf3dc-d3f0-4f44-ca07-09407171ecf7"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY5pNDbLaD2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIKnf5M2aD2i",
        "colab_type": "code",
        "colab": {},
        "outputId": "22fde501-d901-4618-8f97-f58869739d20"
      },
      "source": [
        "torch.Tensor([1.0]).to(torch.device(\"cpu\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "p_2kKUR_aD2k",
        "colab_type": "text"
      },
      "source": [
        "### We need all our tensor ops to be on the GPU \n",
        "\n",
        "Otherwise we will get an error \n",
        "\n",
        "This means we have to put our dataset onto the gpu as well as our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "e1huurNiaD2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_device(x, y):\n",
        "    return x.to(dev), y.to(dev)\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "oxXFuFQgaD2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl, valid_dl = get_data(x_train, y_train, 64)\n",
        "train_dl = WrappedDataLoader(train_dl, to_device)\n",
        "valid_dl = WrappedDataLoader(valid_dl, to_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6DxaqIAoaD2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6XfdQb2FaD2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(dev)\n",
        "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "66U_XCq-aD2u",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b609141-f3eb-4458-bdd2-6567c74ec2b5"
      },
      "source": [
        "%%time\n",
        "fit(10, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.20664597454071046 0.9376977848101266\n",
            "1 0.2013221917152405 0.9416534810126582\n",
            "2 0.199952001953125 0.9433346518987342\n",
            "3 0.18992808513641357 0.9444224683544303\n",
            "4 0.18371812086105346 0.9486748417721519\n",
            "5 0.1758351182937622 0.9511471518987342\n",
            "6 0.16914637775421143 0.9523338607594937\n",
            "7 0.1881415760040283 0.9475870253164557\n",
            "8 0.18738684339523315 0.9472903481012658\n",
            "9 0.17089933853149414 0.9521360759493671\n",
            "CPU times: user 55.7 s, sys: 1min 52s, total: 2min 47s\n",
            "Wall time: 1min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "FDplTF86aD2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}